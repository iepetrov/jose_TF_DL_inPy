# def one_and_one(a,b):
#     return a+b+a*b

# print(one_and_one(3,3))

# print(one_and_one(7,7))




# # Change working directory from the workspace root to the ipynb file location. Turn this addition off with the DataScience.changeDirOnImportExport setting
# # ms-python.python added
# import os
# try:
# 	os.chdir(os.path.join(os.getcwd(), 'Tensorflow-Bootcamp-master\\01-Neural-Network-Basics'))
# 	print(os.getcwd())
# except:
# 	pass

class SimpleClass():
    def __init__(self,name):
        print('hello'+name)
    def yell(self):
        print('YYY')

class ExtendedClass(SimpleClass):
    def __init__(self):
        super().__init__('IvY')
        print('extended')


import numpy as np

class Operation():
    """
    An Operation is a node in a "Graph"
    """
    def __init__(self, input_nodes = []):
        """
        Intialize an Operation
        """
        self.input_nodes = input_nodes 
        self.output_nodes = [] 

        for node in input_nodes:
            node.output_nodes.append(self)
        

        _default_graph.operations.append(self)

        def compute(self):
            pass

class add(Operation):
    
    def __init__(self, x, y):
         
        super().__init__([x, y])

    def compute(self, x_var, y_var):
         
        self.inputs = [x_var, y_var]
        return x_var + y_var

class multiply(Operation):
     
    def __init__(self, a, b):
        
        super().__init__([a, b])
    
    def compute(self, a_var, b_var):
         
        self.inputs = [a_var, b_var]
        return a_var * b_var

class matmul(Operation):
     
    def __init__(self, a, b):
        
        super().__init__([a, b])
    
    def compute(self, a_mat, b_mat):
         
        self.inputs = [a_mat, b_mat]
        return a_mat.dot(b_mat)

class Placeholder():
    """
    A placeholder is a node that needs to be provided a value for computing the output in the Graph.
    """
    def __init__(self):
        
        self.output_nodes = []
        
        _default_graph.placeholders.append(self)

class Variable():

    def __init__(self, initial_value = None):
        
        self.value = initial_value
        self.output_nodes = []
        
         
        _default_graph.variables.append(self)

class Graph():

    def __init__(self):
        
        self.operations = []
        self.placeholders = []
        self.variables = []
        
    def set_as_default(self):
        """
        Sets this Graph instance as the Global Default Graph
        """
        global _default_graph
        _default_graph = self

# ## A Basic Graph
# 
# $$ z = Ax + b $$
# 
# With A=10 and b=1
# 
# $$ z = 10x + 1 $$
# 
# Just need a placeholder for x and then once x is filled in we can solve it!   

##############################
# ex_1
##############################

# g = Graph()

# g.set_as_default()

# A = Variable(10)

# b = Variable(1)

# x = Placeholder()

# y = multiply(A,x)

# z = add(y,b)


########### Exmpl_2 ##############

# g = Graph()

# g.set_as_default()

# A = Variable([[10,20],[30,40]])

# b = Variable([1,1])

# x = Placeholder()

# y = matmul(A,x)

# z = add(y,b)



##############################
# ex_3
##############################

import matplotlib.pyplot as plt

class Sigmoid(Operation):
 
    
    def __init__(self, z):

        # a is the input node
        super().__init__([z])

    def compute(self, z_val):
        
        return 1/(1+np.exp(-z_val))


### Classification Example

from sklearn.datasets import make_blobs

data = make_blobs(n_samples = 50,n_features=2,centers=2,random_state=75)

features = data[0]
plt.scatter(features[:,0],features[:,1])

labels = data[1]
plt.scatter(features[:,0],features[:,1],c=labels,cmap='coolwarm')


g = Graph()

g.set_as_default()

w = Variable([1,1])

b = Variable(-5)

x = Placeholder()

z = add(matmul(w,x),b)

a = Sigmoid(z)







def traverse_postorder(operation):
    """ 
    PostOrder Traversal of Nodes. Basically makes sure computations are done in 
    the correct order (Ax first , then Ax + b). Feel free to copy and paste this code.
    It is not super important for understanding the basic fundamentals of deep learning.
    """
    
    nodes_postorder = []
    def recurse(node):
        if isinstance(node, Operation):
            for input_node in node.input_nodes:
                recurse(input_node)
        nodes_postorder.append(node)

    recurse(operation)
    return nodes_postorder

class Session:
    
    def run(self, operation, feed_dict = {}):
        """ 
          operation: The operation to compute
          feed_dict: Dictionary mapping placeholders to input values (the data)  
        """
        
        # Puts nodes in correct order
        nodes_postorder = traverse_postorder(operation)
        
        for node in nodes_postorder:

            if type(node) == Placeholder:
                
                node.output = feed_dict[node]
                
            elif type(node) == Variable:
                
                node.output = node.value
                
            else: # Operation
                
                node.inputs = [input_node.output for input_node in node.input_nodes]

                 
                node.output = node.compute(*node.inputs)
                
            # Convert lists to numpy arrays
            if type(node.output) == list:
                node.output = np.array(node.output)
        
        # Return the requested node value
        return operation.output

sess = Session()

### EX_2
# result = sess.run(operation=z,feed_dict={x:10})

### EX_3
res1 = sess.run(operation=a,feed_dict={x:[8,10]})

res3 = sess.run(operation=a,feed_dict={x:[2,-5]})
res3 = sess.run(operation=a,feed_dict={x:[2,-10]})

print(result)
result









# #%%
# import matplotlib.pyplot as plt
# # # get_ipython().magic('matplotlib inline')

# # def sigmoid(z):
# #     return 1/(1+np.exp(-z))

# # sample_z = np.linspace(-10,10,100)
# # sample_a = sigmoid(sample_z)

# # plt.plot(sample_z,sample_a)


# #### Sigmoid as an Operation
# class Sigmoid(Operation):
 
    
#     def __init__(self, z):

#         # a is the input node
#         super().__init__([z])

#     def compute(self, z_val):
        
#         return 1/(1+np.exp(-z_val))




# ###
# ###
# ### Classification Example

# from sklearn.datasets import make_blobs

# data = make_blobs(n_samples = 50,n_features=2,centers=2,random_state=75)

# type(data)

# # data[0]
# # data[1]

# features = data[0]
# plt.scatter(features[:,0],features[:,1])

# labels = data[1]
# plt.scatter(features[:,0],features[:,1],c=labels,cmap='coolwarm')




# #%%
# # DRAW A LINE THAT SEPERATES CLASSES
# x = np.linspace(0,11,10)
# y = -x + 5
# plt.scatter(features[:,0],features[:,1],c=labels,cmap='coolwarm')
# plt.plot(x,y)

























print('stop')